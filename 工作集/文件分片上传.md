## 文件分片

> **Hash作用**：计算文件的 MD5 或 SHA-256，作为文件的唯一 ID。服务端通过检查是否已存在相同 Hash 的文件，直接返回“秒传成功”，无需重复上传。

`main.js`

```js
import { cutFile } from './cutFile.js';

const inpFile = document.querySelector('input[type="file"]');

inpFile.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  console.time('cutFile');
  const chunks = await cutFile(file);
  console.timeEnd('cutFile');
  console.log(chunks);
})
```

`cutFile.js`

```js

const CHUNK_SIZE = 1024 * 1024 * 5; // 5MB
const THREAD_COUNT = navigator.hardwareConcurrency || 4; // 计算机上可用于运行线程的逻辑处理器数量

export async function cutFile(file) {
  return new Promise((resolve) => {
    // 分片数量
    const chunkCount = Math.ceil(file.size / CHUNK_SIZE);
    // 每个线程要处理的分片数量
    const threadChunkCount = Math.ceil(chunkCount / THREAD_COUNT);
    const result = [];
    let finishCount = 0;
    for (let i = 0; i < THREAD_COUNT; i++) {
      // 分配线程任务
      const worker = new Worker('./worker.js', {
        type: 'module', // 模块格式
      })
      // 每个线程要处理的分片开始和结束位置
      const start = i * threadChunkCount;
      const end = (i + 1) * threadChunkCount;
      if (end > chunkCount) {
        end = chunkCount;
      }
      worker.postMessage({
        file,
        start,
        end,
        CHUNK_SIZE
      });
      worker.onmessage = function (e) {
        result[i] = e.data;
        worker.terminate();
        finishCount++;
        if (finishCount === THREAD_COUNT) {
          resolve(result.flat())
        }
      };
    }
  });
}
```

`worker.js`

```js
import { createChunk } from './createChunk.js';

onmessage = async function (e) { 
  const {
    file,
    start,
    end,
    CHUNK_SIZE,
  } = e.data;

  const result = [];
  for (let i = start; i < end; i++) {
    const prom = createChunk(file, i, CHUNK_SIZE)
    result.push(prom)
  }
  const chunks = await Promise.all(result);
  postMessage(chunks);
};
```

`createChunk.js`

```js
import SparkMD5 from 'spark-md5'

export function createChunk(file, index, chunkSize) {
  return new Promise((resolve, reject) => { 
    const start = index * chunkSize;
    const end = start + chunkSize;
    const spark = new SparkMD5.ArrayBuffer();
    const fileReader = new FileReader();
    const blob = file.slice(start, end);

    fileReader.onload = function (e) {
      spark.append(e.target.result);
      resolve({
        start,
        end,
        index,
        hash: spark.end(),
        blob
      })
    };
    
    fileReader.readAsArrayBuffer(blob);
  })
}
```

## 分片上传

> 第三方库：**[tus-js-client](https://github.com/tus/tus-js-client)** 客户端（支持断点续传）、**[tus-node-server](https://github.com/tus/tus-node-server)** 服务端

1. **上传分片**

   - 使用 `FormData` 将分片数据上传到服务器。

   - 每个分片上传时携带分片序号、文件唯一标识等信息。

   - 使用 `Promise.all` 并行上传多个分片，提升上传速度。

   - 实时显示上传进度，提升用户体验。

   - 为每个分片设置重试机制，增强上传稳定性。

   - 在上传前对分片进行压缩，减少上传数据量。

     ```js
     // 计算文件唯一标识（MD5）
     function calculateFileHash(file) {
       return new Promise((resolve) => {
         const reader = new FileReader();
         reader.readAsArrayBuffer(file);
         reader.onload = () => {
           const buffer = reader.result;
           const spark = new SparkMD5.ArrayBuffer();
           spark.append(buffer);
           resolve(spark.end());
         };
       });
     }
     
     // 分片上传
     const formData = new FormData();
     formData.append('file', chunk);
     formData.append('chunkIndex', i);
     formData.append('totalChunks', chunks);
     formData.append('fileHash', fileHash);
     ```

2. **服务器合并分片**

   - 服务器接收到所有分片后，按顺序合并分片，还原完整文件。

     ```js
     // 通知服务器合并分片
     fetch('/merge-chunks', {
       method: 'POST',
       headers: {
       	'Content-Type': 'application/json',
       },
     	body: JSON.stringify({ fileHash, fileName }),
     }).then((response) => {
     	if (!response.ok) throw new Error('合并失败');
     });
     
     app.post('/merge-chunks', async (req, res) => {
       const { fileHash, fileName } = req.body;
       const finalPath = `uploads/${fileName}`;
       const writeStream = fs.createWriteStream(finalPath);
     
       for (let i = 0; i < totalChunks; i++) {
         const chunkPath = path.join(uploadDir, `${fileHash}-${i}`);
         const data = fs.readFileSync(chunkPath);
         writeStream.write(data);
         fs.unlinkSync(chunkPath); // 删除临时分片
       }
       writeStream.end();
       res.send('File merged');
     });
     ```

3. **断点续传**
   - **记录已上传的分片**：前端可以在本地存储（如 `localStorage`）中记录已上传的分片，上传失败时从中断处继续上传。
   - **跳过已上传的分片**：在上传前检查分片是否已上传，避免重复上传。

## 文件hash的作用

#### **唯一文件标识（秒传、断点续传）**

- **场景**：用户上传一个 1GB 文件，中途断网或刷新页面。

- **Hash作用**：
  计算文件的 MD5 或 SHA-256，作为文件的唯一 ID。服务端通过检查是否已存在相同 Hash 的文件，直接返回“秒传成功”，无需重复上传。

  JavaScript

  复制

  ```javascript
  // 前端计算文件Hash（spark-md5库）
  const hash = await SparkMD5.ArrayBuffer.hash(fileBuffer);
  ```

  

#### **1.2 分片校验（防篡改）**

- **场景**：分片上传过程中，某个分片因网络错误被篡改。

- **Hash作用**：
  每个分片附带自身 Hash（或整个文件的 Hash），服务端接收后重新计算 Hash 比对，确保数据完整。

  JavaScript

  复制

  ```javascript
  // 分片Hash校验
  const chunkHash = md5(chunk); // 前端计算分片Hash
  // 服务端接收后重新计算chunk的Hash，与前端提交的值比对
  ```

#### **1.3 去重存储（节省空间）**

- **场景**：多个用户上传同一部电影。
- **Hash作用**：
  服务端通过文件 Hash 判断文件已存在，直接引用现有文件，节省存储空间（云盘常用此技术）。

#### **1.4 断点续传的“断点”定位**

- **场景**：上传 50% 时中断，如何知道哪些分片已传？
- **Hash作用**：
  前端将文件 Hash 发送给服务端，服务端返回“已上传的分片列表”（基于 Hash 查询），实现精准续传。

------

### **实际应用中的 Hash 策略**

| **场景**         | **Hash类型**   | **计算时机**       | **作用**                     |
| :--------------- | :------------- | :----------------- | :--------------------------- |
| 文件秒传         | 全文件 MD5     | 上传前计算整个文件 | 服务端判断是否已存在相同文件 |
| 分片完整性校验   | 分片 MD5       | 每片上传前计算     | 防止分片数据损坏             |
| 最终文件合并校验 | 全文件 SHA-256 | 所有分片合并后计算 | 验证最终文件完整性           |

------

### **不计算 Hash 的风险**

- **重复上传**：同一文件多次上传，浪费带宽。
- **数据错误**：分片损坏导致最终文件不可用（如视频无法播放）。
- **存储冗余**：云盘存储多个相同文件副本。

------

### **一句话总结**

> **Hash 是分片上传的“数字指纹”，让文件在传输和存储中具备“可验证、可复用、可恢复”的能力。**